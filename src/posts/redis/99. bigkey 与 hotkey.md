---
date: 2024-04-10
category:
  - 数据库
tag:
  - Redis
excerpt: 大键与热键的产生原因和解决办法
order: 99
---

# bigkey 与 hotkey

## 1. bigkey

占用内存较大的 key

- string 类型的值大于 1 MB
- hash、list、set、zset 类型的元素的个数超过 5000 个
  - 个数多并不代表内存占用也多，主要考虑的还是内存的占用

通常来说，都是由于 key 中的保存的数据太多而导致产生 bigkey

### 1.1 为何产生

- 使用不合理，将大量的数据存放在一个 key 中，最常见的错误
- 业务增长过快，数据量超过程序设计时的预想范围
- 使用集合类型时没有及时清理无效的数据，导致数据量越来越大

### 1.2 有何影响

- 内存占用过高：可能会导致可用内存不足，触发内存淘汰策略，甚至服务直接崩溃
- 性能下降：会占用大量内存空间，导致内存碎片增加，并且对于 bigkey 的操作，会消耗更多的内存和 CPU
- 客户端超时阻塞：因为 Redis 执行命令是单线程的，在操作 bigkey 时会比较耗时，会阻塞 Redis
- 阻塞工作线程：如果使用 `del` 命令删除 bigkey，会阻塞工作线程
- 网络阻塞：每次获取 bigkey 产生的网络流量都比较大，请求这些 bigkey 的频率越高，造成网络阻塞的可能性越大
- 主从同步延迟：bigkey 占用了较多的内存，且网络传输时需要占用更多的带宽，从而导致主从之间的延迟增加，进而影响数据一致性

### 1.3 如何查找

#### 1.3.1 使用 `redis-cli --bigkeys` 命令

会阻塞 Redis，生产环境慎用，如果配置了主从，可以在从节点上执行

- 只能返回每种类型中最大的 key
  - 注意展示的可能并不是 bigkey，只是该类型中数据量最大的 key
- 对于集合类型，只能统计中元素的个数，而不是实际占用的内存

```shell
# Scanning the entire keyspace to find biggest keys as well as
# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec
# per 100 SCAN commands (not usually needed).

[00.00%] Biggest string found so far '"hello"' with 5 bytes
[00.00%] Biggest list   found so far '"books"' with 7 items

-------- summary -------

Sampled 2 keys in the keyspace!
Total key length in bytes is 10 (avg len 5.00)

Biggest   list found '"books"' has 7 items
Biggest string found '"hello"' has 5 bytes

1 lists with 7 items (50.00% of keys, avg size 7.00)
0 hashs with 0 fields (00.00% of keys, avg size 0.00)
1 strings with 5 bytes (50.00% of keys, avg size 5.00)
0 streams with 0 entries (00.00% of keys, avg size 0.00)
0 sets with 0 members (00.00% of keys, avg size 0.00)
0 zsets with 0 members (00.00% of keys, avg size 0.00)
```

#### 1.3.2 使用 `scan` 命令

`scan` 命令可以按照一定的模式和数量返回匹配的 key，获取了 key 之后，再根据类型，使用对应的命令返回长度或元素个数

Redis 4.0 之后，可以使用 `memory usage <key>` 查询占用的内存大小

#### 1.3.3 使用 redis-rdb-tools 扫描 RDB 文件

使用第三方工具扫描 RDB 文件，实时性较差，但不影响使用

### 1.4 如何处理

可以对 bigkey 进行拆分，采用更合适的数据结构，手动清理，但这些方案都绕不过删除

如果一下子把 bigkey 都删除了，可能会阻塞主线程，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常

#### 1.4.1 分批删除

获取到 bigkey，再分批次进行删除

#### 1.4.2 异步删除

Redis 4.0 之后可以使用异步删除法，用 `unlink` 命令代替 `del` 来删除，Redis 会将 key 放入到一个异步线程中进行删除，这样就不会阻塞主线程了

## 2. hotkey

对于某个 key 的请求远远大于其他 key，造成流量过于集中，很可能导致服务器的崩溃

### 2.1 为何产生

开发人员未能很好的评估数据的请求量，或者偶发事件造成的对同一数据的过量请求

常出现于用户消费的数据远大于生产的场景，例如热搜事件、秒杀活动

### 2.2 有何影响

- 占用大量的 CPU 及带宽：如果超过了服务器的处理能力，就会发生崩溃。大量请求直接落在数据库上，甚至可能会导致服务雪崩
- 影响同一 Redis 实例下其他 key 的读写操作

### 2.3 如何查找

#### 2.3.1 使用 `redis-cli --hotkeys` 命令

与 `redis-cli --bigkeys` 类似，返回所有 key 的被访问次数

- 但要注意该命令需要进行全局扫描，实时性较差，也会增加服务器的 CPU 和内存消耗
- 必须使用 LFU 的内存淘汰策略，否则会报错
  - volatile-lfu 或 allkeys-lfu

```shell
# Scanning the entire keyspace to find hot keys as well as
# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec
# per 100 SCAN commands (not usually needed).


-------- summary -------

Sampled 2 keys in the keyspace!
```

#### 2.3.2 使用 `monitor` 命令

实时查看 Redis 的所有操作，可以用于临时监控 Redis 实例的操作情况，包括读写、删除等操作。但对 Redis 的性能影响较大，谨慎使用

```shell
> monitor
OK
1712728016.641569 [0 172.17.0.1:51412] "ping"
1712728022.074532 [0 172.17.0.1:51426] "get" "hello"
1712728026.007182 [0 172.17.0.1:51412] "ping"
1712728033.795193 [0 172.17.0.1:51426] "set" "test" "\xe6\xb5\x8b\xe8\xaf\x95\xe7\x9a\x84"
1712728036.652536 [0 172.17.0.1:51412] "ping"
```

### 2.4 如何处理

最好的方法就是根据业务情况提前预估请求量，但总是无法避免一些偶然事件

#### 2.4.1 二级缓存

将 hotkey 存放一份到本地缓存中，后续就直接从本地缓存中获取

- 需要注意数据的大小和一致性

#### 2.4.2 读写分离

主节点处理写请求，从节点处理读请求

## 参考

- [面试官：Redis 大 key 要如何处理？](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247518433&idx=2&sn=e78f630c07f4e60fb78999eb3d742e9e&chksm=f98dcc4bcefa455d8ffde9ad6c8da9b3371a401766a55cbee7af11c87be070d823c8d5926aef&scene=178&cur_album_id=1790401816640225283)
- [深入研究Redis大Key问题与解决方案](https://juejin.cn/post/7167015025154981895)
- [Redis性能瓶颈揭秘：如何优化大key问题？](https://zhuanlan.zhihu.com/p/622474134)
- [Redis 热 Key 发现以及解决办法](https://dongzl.github.io/2021/01/14/03-Redis-Hot-Key/index.html)
- [『超级架构师』Redis热key的发现与解决](https://juejin.cn/post/7010231093664153613)
